JOINT
    Avg AUC = 0.757
    total correctFalse = 1360
    total correctTrue = 335
    total wrongFalse = 416
    total wrongTrue = 206
    total accuracy = 0.7315494173500215
    true accuracy = 0.6192236598890942
    false accuracy = 0.7657657657657657
    false precision = 0.8684546615581098
    false recall = 0.7657657657657657
    false F1 = 0.8138839018551766


FULL DISTANT SUP TESTING
    Avg AUC = 0.762
    total correctFalse = 1236
    total correctTrue = 354
    total wrongFalse = 537
    total wrongTrue = 187
    total accuracy = 0.6871218668971478
    true accuracy = 0.6543438077634011
    false accuracy = 0.6971235194585449
    false precision = 0.8685874912157414
    false recall = 0.6971235194585449
    false F1 = 0.7734668335419276

    Avg AUC = 0.6273546539838786
    total correctFalse = 1173
    total correctTrue = 371
    total wrongFalse = 600
    total wrongTrue = 170
    total accuracy = 0.6672428694900605
    true accuracy = 0.6857670979667283
    false accuracy = 0.6615905245346869
    false precision = 0.8734177215189873
    false recall = 0.6615905245346869
    false F1 = 0.7528883183568678



STANCE + reliability
    Avg AUC = 0.6600018118740435
    total correctFalse = 1170
    total correctTrue = 394
    total wrongFalse = 603
    total wrongTrue = 147
    total accuracy = 0.675885911840968
    true accuracy = 0.7282809611829945
    false accuracy = 0.6598984771573604
    false precision = 0.8883826879271071
    false recall = 0.6598984771573604
    false F1 = 0.7572815533980582

Stance + linguistic
    Avg AUC = 0.7047529958002048
    total correctFalse = 1324
    total correctTrue = 304
    total wrongFalse = 449
    total wrongTrue = 237
    total accuracy = 0.7035436473638721
    true accuracy = 0.5619223659889094
    false accuracy = 0.7467569091934574
    false precision = 0.8481742472773863
    false recall = 0.7467569091934574
    false F1 = 0.794241151769646

Stance
    Avg AUC = 0.742122659376973
    total correctFalse = 1100
    total correctTrue = 374
    total wrongFalse = 673
    total wrongTrue = 167
    total accuracy = 0.6369922212618842
    true accuracy = 0.6913123844731978
    false accuracy = 0.6204173716864072
    false precision = 0.8681925808997633
    false recall = 0.6204173716864072
    false F1 = 0.7236842105263157

LINGUISTIC FEATURES
    Avg AUC = 0.6029158749997351
    total correctFalse = 1051
    total correctTrue = 299
    total wrongFalse = 722
    total wrongTrue = 242
    total accuracy = 0.5834053586862575
    true accuracy = 0.5526802218114603
    false accuracy = 0.59278059785674
    false precision = 0.8128383604021655
    false recall = 0.59278059785674
    false F1 = 0.6855838225701238

LINGUISTIC FEATURES + reliability
    Avg AUC = 0.5115196012731331
    total correctFalse = 1053
    total correctTrue = 300
    total wrongFalse = 720
    total wrongTrue = 241
    total accuracy = 0.5847018150388937
    true accuracy = 0.5545286506469501
    false accuracy = 0.5939086294416244
    false precision = 0.8137557959814529
    false recall = 0.5939086294416244
    false F1 = 0.6866644929898924


Wiki Hoax performance
    Distant Supervision Model - ../resources//models/distantSupervisionV2M3.model
    claims = 109
    wrongFalse = 14
    wrongTrue = 0
    accuracy = 0.8715596330275229

Wiki Ficticious People performance
    Distant Supervision Model - 
    claims = 55
    wrongFalse = 8
    wrongTrue = 0
    accuracy = 0.8545454545454545
    

Social Media
    Only social media sources
        total accuracy = 0.6266233766233766
        true accuracy = 0.6301369863013698
        false accuracy = 0.625531914893617

    Full article set
        total accuracy = 0.7612903225806451
        true accuracy = 0.8082191780821918
        false accuracy = 0.7468354430379747



Long Tail Claims

articles >= 3 --> 0.626
    total accuracy = 0.6083333333333333
    true accuracy = 0.6567164179104478
    false accuracy = 0.5972696245733788
articles >= 6 --> 0.605
    total accuracy = 0.6214285714285714
    true accuracy = 0.5808823529411765
    false accuracy = 0.6312056737588653 
articles >= 9 --> 0.614
    total accuracy = 0.6373106060606061
    true accuracy = 0.57847533632287
    false accuracy = 0.6530612244897959
articles >= 12 --> 0.64
    total accuracy = 0.6512784090909091
    true accuracy = 0.6215384615384615
    false accuracy = 0.6602031394275162
articles >= 15 --> 0.645
    total accuracy = 0.6632768361581921
    true accuracy = 0.637717121588089py
articles >= 18 --> 0.66
    total accuracy = 0.665545410860163
    true accuracy = 0.6652806652806653
    false accuracy = 0.665625
articles >= 21 --> 0.670
    total accuracy = 0.666369710467706
    true accuracy = 0.6782273603082851
    false accuracy = 0.6628041714947857
articles >= 24 --> 0.6715
    total accuracy = 0.6665215498476273
    true accuracy = 0.6828358208955224
    false accuracy = 0.6615559341283361
articles >= 27 --> 0.67335
    total accuracy = 0.666955017301038
    true accuracy = 0.6857670979667283
    false accuracy = 0.6612083568605308
articles >= 30 --> 0.673
    0.666955017301038
    0.6857670979667283
    0.6612083568605308
************************
Notes
************************
143 -> duplicate articles
3573 false -> 3436 false

True --> 1277
False --> 3436
False/True --> 2.6906812842599845
               ~2.7

A portion of the linguistic features lexicon was solely available on the webpage of a Cornel researcher who has moved on from Cornel
    - the data has since been removed from their site
    - http://www.mpi-sws.org/Ëœcristian/Biased_language.html

Eventually directed me wordnet
Lexcon
    - University of Illinois at Chicago
        - https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#:~:targetText=Opinion%20Lexicon%3A%20A%20list%20of,words%20(around%206800%20words).&targetText=Although%20necessary%2C%20having%20an%20opinion,or%20the%20Sentiment%20Analysis%20book.
    S. Mukherjee, G. Weikum, and C. Danescu-Niculescu-Mizil.
    People on drugs: Credibility of user statements in health
    communities. KDD, 2014.
        - http://resources.mpi-inf.mpg.de/impact/peopleondrugs/peopleondrugs-kdd2014.pdf
    Theresa Wilson, Janyce Wiebe and Paul Hoffmann (2005). Recognizing Contextual 
    Polarity in Phrase-Level Sentiment Analysis. Proceedings of HLT/EMNLP 2005,
    Vancouver, Canada.
        - 

Assertive:
    - claim
    - saw
Factive:
    - indicate
    - indicates
    - indicated
    - reveal
    - reveals
    - revealed
    - showedq
    - show
    - shows
    - declare
    - declared
    - declares
Hedge:
    - may
Implicatives:
    - complicit
Report:
    - argue
    - refute
    - 
Discourse:
    - could
    - if
    - maybe
    - should
    - therefore
    - actually
    - although
    - but
************************
To Do
************************
- Web Scraper
    - BeautifulSoup
    - Grabs first 30 results from google search
        - Takes body

- Stance Determination
    - liblinearutil
        - train()
            -> -s 6  L1 regularized logistic regression
            -> -wi 4 -c 1 weight support more heavily to balance training data

- Predicting
    - -> -q for quiet prediction
    - -> -b 1 for full prob output

Google Search
    - https://www.google.com/search?q=test+this
        import requests
        def googleSearch(query):
            with requests.session() as c:
                url = 'https://www.google.co.in'
                query = {'q': query}
                urllink = requests.get(url, params=query)
                print urllink.url
        googleSearch('Linkin Park')


- Credibility Assessment
    - During testing
        - Keep track of # of correct stances and incorrect stances
    - Reliability = sum(supportWhenTrue, refuteWhenFalst)/#articles
    - 0.5 is baseline
        - If websource not previously seen (or maybe not enough evidence?)

************************
Resources
************************
    Web Scraping
        - BeautifulSoup
            - Dissect HTML files
            - https://www.geeksforgeeks.org/performing-google-search-using-python-code/
        - Scrapy
            - Pull html pages
        - Selenium?

    NLTK
        - Punctuation counts as a word, can remove it
        - Chunk sentences
        - Use to remove people's and place's names (NNP...)
        - https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/

    LibLinear -> classifier
        - https://www.csie.ntu.edu.tw/~cjlin/liblinear/#download
    
    sklearn
        - python machine learning lib?


************************
Extensions??
************************
- See how well article titles predict validity 
- Measure overlap of stemmed claims and articles

- Replace named entity of the claim in the article with stemmed? 
    - Or with 'ClaimEntity'
    - Check bigram and trigram interactions?
